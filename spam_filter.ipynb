{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swami\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import chardet \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spam.csv\", 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "#print(result['encoding'])\n",
    "df = pd.read_csv('spam.csv', encoding=result['encoding'])\n",
    "df=df.loc[:,'v1':'v2']\n",
    "df=df.rename(index=str, columns={\"v1\": \"status\", \"v2\": \"message\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model\n",
    "I split the data set into test and train. Using train set I find the most freqently occurring words in spam sms's.\n",
    "Then I modify the dataframe and give in new features to the model.\n",
    "I use the test data to calculate accuracies and other statistics.\n",
    "The naive model classifies an sms as spam when one of the frequently occurring spam words is found in the sms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "d={}\n",
    "def tfidf (a,s):#a is the spam ham list \n",
    "    for i in range(len(a)):\n",
    "        if s[i]==\"spam\":\n",
    "            for x in list(a[i].split(' ')):\n",
    "                d[x]=[0,0]\n",
    "                \n",
    "    for i in range(len(a)):\n",
    "        if s[i]==\"spam\":\n",
    "            for x in list(a[i].split(' ')):\n",
    "                d[x][0]=d[x][0]+1\n",
    "            for x in set(list(a[i].split(' '))):\n",
    "                d[x][1]=d[x][1]+1\n",
    "        \n",
    "tfidf(X_train,y_train)\n",
    "k=len(X_train)\n",
    "for x in d:\n",
    "    d[x]=d[x][0]*np.log((k/d[x][1])) \n",
    "d=sorted(d.items(), key=operator.itemgetter(1))\n",
    "# frequently occurring spamwords picked manually \n",
    "# FREE  Free won NOW! chance CALL Send Please Get service STOP cash prize\n",
    "def change(x):\n",
    "    if(x == 'ham'):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def frq(x):\n",
    "    return(int('STOP' in x )+int('prize' in x )+int('cash' in x )+int('service' in x )+int('Get' in x )+\n",
    "           int('Please' in x )+int('Send' in x )+int('CALL' in x )+int('chance' in x )+int('NOW!' in x )+\n",
    "           int('won' in x )+int('Free' in x )+int('FREE' in x ))\n",
    "\n",
    "df['status'] = df['status'].map(lambda x : change(x))\n",
    "df['len'] = df['message'].map(lambda x: len(x))\n",
    "df['FREE'] = df['message'].map(lambda x: int('FREE' in x ))\n",
    "df['Free'] = df['message'].map(lambda x: int('Free' in x ))\n",
    "df['won'] = df['message'].map(lambda x: int('won' in x ))\n",
    "df['NOW!'] = df['message'].map(lambda x: int('NOW!' in x ))\n",
    "df['chance'] = df['message'].map(lambda x: int('chance' in x ))\n",
    "df['CALL'] = df['message'].map(lambda x: int('CALL' in x ))\n",
    "df['Send'] = df['message'].map(lambda x: int('Send' in x ))\n",
    "df['Please'] = df['message'].map(lambda x: int('Please' in x ))\n",
    "df['Get'] = df['message'].map(lambda x: int('Get' in x ))\n",
    "df['service'] = df['message'].map(lambda x: int('service' in x ))\n",
    "df['cash'] = df['message'].map(lambda x: int('cash' in x ))\n",
    "df['prize'] = df['message'].map(lambda x: int('prize' in x ))\n",
    "df['STOP'] = df['message'].map(lambda x: int('STOP' in x ))\n",
    "df['freq'] = df['message'].map(lambda x : frq(x))\n",
    "gg=[]\n",
    "true_positive=0\n",
    "true_negative=0\n",
    "false_positive=0\n",
    "false_negative=0\n",
    "for i in range(len(X_test)):\n",
    "    gg.append([X_test[i],y_test[i],frq(X_test[i])])\n",
    "    if y_test[i]==\"spam\":\n",
    "        if frq(X_test[i])==0:\n",
    "            false_positive=false_positive+1\n",
    "        else:\n",
    "            true_positive=true_positive+1\n",
    "    else:\n",
    "        if frq(X_test[i])==0:\n",
    "            true_negative=false_negative+1\n",
    "        else:\n",
    "            true_negative=true_negative+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.49740932642487046\n",
      "precision 0.4947916666666667\n",
      "recall 1.0\n",
      "f1 0.662020905923345\n"
     ]
    }
   ],
   "source": [
    "precision=true_positive/(true_positive+false_positive)\n",
    "recall=true_positive/(true_positive+false_negative)\n",
    "print(\"accuracy\",(true_negative+true_positive)/(true_negative+true_positive+false_negative+false_positive))\n",
    "print(\"precision\",precision)\n",
    "print(\"recall\",recall)\n",
    "print(\"f1\",2*precision*recall/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "Decision trees are built by choosing the right attribute at each node of a tree. The attribute is chosen such that the information gain is high among all attributes. Entropy and Gini Index are the most commonly used function for a decision tree classifier. I have used Gini Index for this classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "Confusion Matrix:  [[1183   18]\n",
      " [ 120   72]]\n",
      "Accuracy :  90.09332376166547\n",
      "Report :               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.94      1201\n",
      "          1       0.80      0.38      0.51       192\n",
      "\n",
      "avg / total       0.89      0.90      0.89      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_dt = df[['len','FREE','Free','won','NOW!','chance','cash','prize','freq']]\n",
    "y_dt = df['status']\n",
    "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X_dt, y_dt, random_state=10)\n",
    "\n",
    "      \n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    return y_pred \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "clf_gini = train_using_gini(X_train_dt, X_test_dt, y_train_dt)      \n",
    "# Prediction using gini \n",
    "y_pred_gini = prediction(X_test_dt, clf_gini) \n",
    "cal_accuracy(y_test_dt, y_pred_gini) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.\n",
    "One big advantage of random forest is, that it can be used for both classification and regression problems. Random Forest has nearly the same hyperparameters as a decision tree or a bagging classifier. Random Forest adds additional randomness to the model, while growing the trees. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9109834888729361\n",
      "f1 0.581081081081081\n",
      "confusion_matrix [[1183   18]\n",
      " [ 106   86]]\n"
     ]
    }
   ],
   "source": [
    "X_rf = df[['len','FREE','Free','won','NOW!','chance','cash','prize','freq']]\n",
    "y_rf = df['status']\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, random_state=10)\n",
    "rf = RandomForestClassifier(n_estimators=20, max_depth=5, criterion= \"entropy\")\n",
    "train_features = np.array(X_train_rf) \n",
    "train_labels = np.array(y_train_rf)\n",
    "rf.fit(train_features, train_labels) \n",
    "test_features = np.array(X_test_rf) \n",
    "test_labels = np.array(y_test_rf) \n",
    "test_predict = rf.predict(test_features)\n",
    "\n",
    "\n",
    "print(\"accuracy\",accuracy_score(test_predict, test_labels))\n",
    "print(\"f1\",f1_score(test_predict, test_labels, average = 'binary'))\n",
    "print(\"confusion_matrix\",confusion_matrix(test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
